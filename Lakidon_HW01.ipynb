{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Optimization problem example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a circular cylindrical can:\n",
    "$$S = 2 \\pi r^2 + 2 \\pi r h$$\n",
    "$$V = \\pi r^2 h$$\n",
    "Hence:\n",
    "$h = \\frac{V}{\\pi r^2}$ and \n",
    "$$S = 2 \\pi r^2 + \\frac{2V}{r}$$\n",
    "Then \n",
    "$$\\frac{dS}{dr} = 4 \\pi r_* - \\frac{2V}{r_*^2} = 0$$\n",
    "\n",
    "$$r_* = \\left(\\frac{V}{2 \\pi} \\right)^{1/3}$$\n",
    "\n",
    "But also we can derive $r = \\sqrt{\\frac{V}{\\pi h}}$\n",
    "$$S = \\frac{2V}{h} + 2\\sqrt{V \\pi h}$$\n",
    "\n",
    "$$\\frac{dS}{dh} = -\\frac{2V}{h_*^2} + \\sqrt{\\frac{V \\pi}{h_*}} = 0$$\n",
    "\n",
    "$$h_* = \\left(2\\sqrt{\\frac{V}{\\pi}} \\right)^{2/3} = 2r_*$$\n",
    "\n",
    "So, $r_* = \\left(\\frac{V}{2 \\pi} \\right)^{1/3}$, $h_* = 2r_*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 Optimality conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find an optimum: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial f}{\\partial x_1} = 3 x_1 + (1 + a) x_2 - 1 = 0$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x_1} = 3 x_2 + (1 + a) x_1 - 1 = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can derive \n",
    "\n",
    "$$x_1 = \\frac{1 - (1 + a)x_2}{3}$$\n",
    "\n",
    "then\n",
    "\n",
    "$$3 x_2 + \\frac{(1 + a)}{3} - \\frac{(1 + a)^2 x_2}{3} - 1 = 0$$\n",
    "\n",
    "$$x_2 = \\frac{(3 - (1 + a))}{(3 - (1 + a))(3 + (1 + a))} = \\frac{1}{a + 4}, \\ \\ \\ \\text{if} \\ \\ a \\neq -4, 2$$\n",
    "\n",
    "$$x_1 = \\frac{1}{a + 4}, \\ \\ \\ \\text{if} \\ \\ a \\neq -4, 2$$\n",
    "\n",
    "If $a = -4$ system has no solution, if $a = 2$, then\n",
    "\n",
    "$$x_1 = \\frac{1 - 3 x_2}{3}$$\n",
    "\n",
    "and system has infinite number of solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let us check the sufficient condition:\n",
    "\n",
    "$$\\frac{\\partial^2 f}{\\partial^2 x_1} = \\frac{\\partial^2 f}{\\partial^2 x_2} = 3$$\n",
    "\n",
    "$$\\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} = \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} = 1 + a $$\n",
    "\n",
    "Hessian of this function is \n",
    "\n",
    "$$H = \\begin{pmatrix}\n",
    "3 & (1+a) \\\\\n",
    "(1+a) & 3\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "If $H$ is positive definite, then $f$ has a minimum value. \n",
    "\n",
    "$3 > 0$, then $H$ is positive definite if $det(H)>0$, then $9 - (1 + a)^2 > 0$, \n",
    "\n",
    "$|1 + a| < 3$, i.e. $a \\in (-4, 2)$\n",
    "\n",
    "So, problem has unique optimtimal solution if $a \\in (-4, 2)$ and $b$ is an arbitrary number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Nelder Mead method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birds(x):\n",
    "    if (x[0] + 5)**2 + (x[1] + 5)**2 < 25:\n",
    "        return np.sin(x[1]) * np.exp((1 - np.cos(x[0]))**2) + np.cos(x[0]) * np.exp((1 - np.sin(x[1]))**2) + (x[0] - x[1])**2\n",
    "    else:\n",
    "        return np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the Nelder-Mead method is already implemented in ```scipy```, so we can use the function from there.\n",
    "\n",
    "We start from the initial point $x_0 = (-3, -4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -106.764537\n",
      "         Iterations: 38\n",
      "         Function evaluations: 75\n"
     ]
    }
   ],
   "source": [
    "sim = minimize(birds, x0 = [-3., -4.], method='Nelder-Mead', options={'disp': True, 'return_all': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = sim.get('allvecs')\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(values)):\n",
    "    x.append(values[i][0])\n",
    "    y.append(values[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, 10)\n",
    "plt.xlim([-10, 0])\n",
    "plt.ylim([-10, 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local optimal point is [-3.13021145 -1.58214571]\n"
     ]
    }
   ],
   "source": [
    "x_star = sim.get('x')\n",
    "print(f'The local optimal point is {x_star}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start from the differnet initial point\n",
    "\n",
    "Now we start from the initial point $x_0 = (-4, -6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -87.310883\n",
      "         Iterations: 37\n",
      "         Function evaluations: 72\n"
     ]
    }
   ],
   "source": [
    "sim = minimize(birds, x0 = [-4., -6.], method='Nelder-Mead', options={'disp': True, 'return_all': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = sim.get('allvecs')\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(values)):\n",
    "    x.append(values[i][0])\n",
    "    y.append(values[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, 10)\n",
    "plt.xlim([-10, 0])\n",
    "plt.ylim([-10, 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that method has converged to another point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another local optimal point is [-3.17576194 -7.81986757]\n"
     ]
    }
   ],
   "source": [
    "x_star = sim.get('x')\n",
    "print(f'Another local optimal point is {x_star}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of function evaluations is 72\n"
     ]
    }
   ],
   "source": [
    "oracle_calls = sim.get('nfev')\n",
    "print(f'The number of function evaluations is {oracle_calls}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the behavior of the method for various parameters we need to go deeper in ```scipy``` code and chage parameters there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import (atleast_1d, eye, mgrid, argmin, zeros, shape, squeeze,\n",
    "                   vectorize, asarray, sqrt, Inf, asfarray, isinf)\n",
    "\n",
    "_status_message = {'success': 'Optimization terminated successfully.',\n",
    "                   'maxfev': 'Maximum number of function evaluations has '\n",
    "                              'been exceeded.',\n",
    "                   'maxiter': 'Maximum number of iterations has been '\n",
    "                              'exceeded.',\n",
    "                   'pr_loss': 'Desired error not necessarily achieved due '\n",
    "                              'to precision loss.'}\n",
    "\n",
    "class OptimizeResult(dict):\n",
    "    \"\"\" Represents the optimization result.\n",
    "    Attributes\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        The solution of the optimization.\n",
    "    success : bool\n",
    "        Whether or not the optimizer exited successfully.\n",
    "    status : int\n",
    "        Termination status of the optimizer. Its value depends on the\n",
    "        underlying solver. Refer to `message` for details.\n",
    "    message : str\n",
    "        Description of the cause of the termination.\n",
    "    fun, jac, hess: ndarray\n",
    "        Values of objective function, its Jacobian and its Hessian (if\n",
    "        available). The Hessians may be approximations, see the documentation\n",
    "        of the function in question.\n",
    "    hess_inv : object\n",
    "        Inverse of the objective function's Hessian; may be an approximation.\n",
    "        Not available for all solvers. The type of this attribute may be\n",
    "        either np.ndarray or scipy.sparse.linalg.LinearOperator.\n",
    "    nfev, njev, nhev : int\n",
    "        Number of evaluations of the objective functions and of its\n",
    "        Jacobian and Hessian.\n",
    "    nit : int\n",
    "        Number of iterations performed by the optimizer.\n",
    "    maxcv : float\n",
    "        The maximum constraint violation.\n",
    "    Notes\n",
    "    -----\n",
    "    There may be additional attributes not listed above depending of the\n",
    "    specific solver. Since this class is essentially a subclass of dict\n",
    "    with attribute accessors, one can see which attributes are available\n",
    "    using the `keys()` method.\n",
    "    \"\"\"\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.keys():\n",
    "            m = max(map(len, list(self.keys()))) + 1\n",
    "            return '\\n'.join([k.rjust(m) + ': ' + repr(v)\n",
    "                              for k, v in sorted(self.items())])\n",
    "        else:\n",
    "            return self.__class__.__name__ + \"()\"\n",
    "\n",
    "    def __dir__(self):\n",
    "        return list(self.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_unknown_options(unknown_options):\n",
    "    if unknown_options:\n",
    "        msg = \", \".join(map(str, unknown_options.keys()))\n",
    "        # Stack level 4: this is called from _minimize_*, which is\n",
    "        # called from another function in Scipy. Level 4 is the first\n",
    "        # level in user code.\n",
    "        warnings.warn(\"Unknown solver options: %s\" % msg, OptimizeWarning, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_function(function, args):\n",
    "    ncalls = [0]\n",
    "    if function is None:\n",
    "        return ncalls, None\n",
    "\n",
    "    def function_wrapper(*wrapper_args):\n",
    "        ncalls[0] += 1\n",
    "        return function(*(wrapper_args + args))\n",
    "\n",
    "    return ncalls, function_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minimize_neldermead(func, x0, rho=1, chi=2, psi=0.5, sigma=0.5, args=(), callback=None,\n",
    "                         maxiter=None, maxfev=None, disp=False,\n",
    "                         return_all=False, initial_simplex=None,\n",
    "                         xatol=1e-4, fatol=1e-4, adaptive=False,\n",
    "                         **unknown_options):\n",
    "    \"\"\"\n",
    "    Minimization of scalar function of one or more variables using the\n",
    "    Nelder-Mead algorithm.\n",
    "    Options\n",
    "    -------\n",
    "    disp : bool\n",
    "        Set to True to print convergence messages.\n",
    "    maxiter, maxfev : int\n",
    "        Maximum allowed number of iterations and function evaluations.\n",
    "        Will default to ``N*200``, where ``N`` is the number of\n",
    "        variables, if neither `maxiter` or `maxfev` is set. If both\n",
    "        `maxiter` and `maxfev` are set, minimization will stop at the\n",
    "        first reached.\n",
    "    initial_simplex : array_like of shape (N + 1, N)\n",
    "        Initial simplex. If given, overrides `x0`.\n",
    "        ``initial_simplex[j,:]`` should contain the coordinates of\n",
    "        the j-th vertex of the ``N+1`` vertices in the simplex, where\n",
    "        ``N`` is the dimension.\n",
    "    xatol : float, optional\n",
    "        Absolute error in xopt between iterations that is acceptable for\n",
    "        convergence.\n",
    "    fatol : number, optional\n",
    "        Absolute error in func(xopt) between iterations that is acceptable for\n",
    "        convergence.\n",
    "    adaptive : bool, optional\n",
    "        Adapt algorithm parameters to dimensionality of problem. Useful for\n",
    "        high-dimensional minimization [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Gao, F. and Han, L.\n",
    "       Implementing the Nelder-Mead simplex algorithm with adaptive\n",
    "       parameters. 2012. Computational Optimization and Applications.\n",
    "       51:1, pp. 259-277\n",
    "    \"\"\"\n",
    "    if 'ftol' in unknown_options:\n",
    "        warnings.warn(\"ftol is deprecated for Nelder-Mead,\"\n",
    "                      \" use fatol instead. If you specified both, only\"\n",
    "                      \" fatol is used.\",\n",
    "                      DeprecationWarning)\n",
    "        if (np.isclose(fatol, 1e-4) and\n",
    "                not np.isclose(unknown_options['ftol'], 1e-4)):\n",
    "            # only ftol was probably specified, use it.\n",
    "            fatol = unknown_options['ftol']\n",
    "        unknown_options.pop('ftol')\n",
    "    if 'xtol' in unknown_options:\n",
    "        warnings.warn(\"xtol is deprecated for Nelder-Mead,\"\n",
    "                      \" use xatol instead. If you specified both, only\"\n",
    "                      \" xatol is used.\",\n",
    "                      DeprecationWarning)\n",
    "        if (np.isclose(xatol, 1e-4) and\n",
    "                not np.isclose(unknown_options['xtol'], 1e-4)):\n",
    "            # only xtol was probably specified, use it.\n",
    "            xatol = unknown_options['xtol']\n",
    "        unknown_options.pop('xtol')\n",
    "\n",
    "    _check_unknown_options(unknown_options)\n",
    "    maxfun = maxfev\n",
    "    retall = return_all\n",
    "\n",
    "    fcalls, func = wrap_function(func, args)\n",
    "\n",
    "    if adaptive:\n",
    "        dim = float(len(x0))\n",
    "        rho = 1\n",
    "        chi = 1 + 2/dim\n",
    "        psi = 0.75 - 1/(2*dim)\n",
    "        sigma = 1 - 1/dim\n",
    "    else:\n",
    "        ################################################################################################################\n",
    "        ##########################################PARAMETERS############################################################\n",
    "        ################################################################################################################\n",
    "        rho = rho\n",
    "        chi = chi\n",
    "        psi = psi\n",
    "        sigma = sigma\n",
    "        ################################################################################################################\n",
    "        ################################################################################################################\n",
    "        ################################################################################################################\n",
    "\n",
    "    nonzdelt = 0.05\n",
    "    zdelt = 0.00025\n",
    "\n",
    "    x0 = asfarray(x0).flatten()\n",
    "\n",
    "    if initial_simplex is None:\n",
    "        N = len(x0)\n",
    "\n",
    "        sim = numpy.zeros((N + 1, N), dtype=x0.dtype)\n",
    "        sim[0] = x0\n",
    "        for k in range(N):\n",
    "            y = numpy.array(x0, copy=True)\n",
    "            if y[k] != 0:\n",
    "                y[k] = (1 + nonzdelt)*y[k]\n",
    "            else:\n",
    "                y[k] = zdelt\n",
    "            sim[k + 1] = y\n",
    "    else:\n",
    "        sim = np.asfarray(initial_simplex).copy()\n",
    "        if sim.ndim != 2 or sim.shape[0] != sim.shape[1] + 1:\n",
    "            raise ValueError(\"`initial_simplex` should be an array of shape (N+1,N)\")\n",
    "        if len(x0) != sim.shape[1]:\n",
    "            raise ValueError(\"Size of `initial_simplex` is not consistent with `x0`\")\n",
    "        N = sim.shape[1]\n",
    "\n",
    "    if retall:\n",
    "        allvecs = [sim[0]]\n",
    "\n",
    "    # If neither are set, then set both to default\n",
    "    if maxiter is None and maxfun is None:\n",
    "        maxiter = N * 200\n",
    "        maxfun = N * 200\n",
    "    elif maxiter is None:\n",
    "        # Convert remaining Nones, to np.inf, unless the other is np.inf, in\n",
    "        # which case use the default to avoid unbounded iteration\n",
    "        if maxfun == np.inf:\n",
    "            maxiter = N * 200\n",
    "        else:\n",
    "            maxiter = np.inf\n",
    "    elif maxfun is None:\n",
    "        if maxiter == np.inf:\n",
    "            maxfun = N * 200\n",
    "        else:\n",
    "            maxfun = np.inf\n",
    "\n",
    "    one2np1 = list(range(1, N + 1))\n",
    "    fsim = numpy.zeros((N + 1,), float)\n",
    "\n",
    "    for k in range(N + 1):\n",
    "        fsim[k] = func(sim[k])\n",
    "\n",
    "    ind = numpy.argsort(fsim)\n",
    "    fsim = numpy.take(fsim, ind, 0)\n",
    "    # sort so sim[0,:] has the lowest function value\n",
    "    sim = numpy.take(sim, ind, 0)\n",
    "\n",
    "    iterations = 1\n",
    "\n",
    "    while (fcalls[0] < maxfun and iterations < maxiter):\n",
    "        if (numpy.max(numpy.ravel(numpy.abs(sim[1:] - sim[0]))) <= xatol and\n",
    "                numpy.max(numpy.abs(fsim[0] - fsim[1:])) <= fatol):\n",
    "            break\n",
    "\n",
    "        xbar = numpy.add.reduce(sim[:-1], 0) / N\n",
    "        xr = (1 + rho) * xbar - rho * sim[-1]\n",
    "        fxr = func(xr)\n",
    "        doshrink = 0\n",
    "\n",
    "        if fxr < fsim[0]:\n",
    "            xe = (1 + rho * chi) * xbar - rho * chi * sim[-1]\n",
    "            fxe = func(xe)\n",
    "\n",
    "            if fxe < fxr:\n",
    "                sim[-1] = xe\n",
    "                fsim[-1] = fxe\n",
    "            else:\n",
    "                sim[-1] = xr\n",
    "                fsim[-1] = fxr\n",
    "        else:  # fsim[0] <= fxr\n",
    "            if fxr < fsim[-2]:\n",
    "                sim[-1] = xr\n",
    "                fsim[-1] = fxr\n",
    "            else:  # fxr >= fsim[-2]\n",
    "                # Perform contraction\n",
    "                if fxr < fsim[-1]:\n",
    "                    xc = (1 + psi * rho) * xbar - psi * rho * sim[-1]\n",
    "                    fxc = func(xc)\n",
    "\n",
    "                    if fxc <= fxr:\n",
    "                        sim[-1] = xc\n",
    "                        fsim[-1] = fxc\n",
    "                    else:\n",
    "                        doshrink = 1\n",
    "                else:\n",
    "                    # Perform an inside contraction\n",
    "                    xcc = (1 - psi) * xbar + psi * sim[-1]\n",
    "                    fxcc = func(xcc)\n",
    "\n",
    "                    if fxcc < fsim[-1]:\n",
    "                        sim[-1] = xcc\n",
    "                        fsim[-1] = fxcc\n",
    "                    else:\n",
    "                        doshrink = 1\n",
    "\n",
    "                if doshrink:\n",
    "                    for j in one2np1:\n",
    "                        sim[j] = sim[0] + sigma * (sim[j] - sim[0])\n",
    "                        fsim[j] = func(sim[j])\n",
    "\n",
    "        ind = numpy.argsort(fsim)\n",
    "        sim = numpy.take(sim, ind, 0)\n",
    "        fsim = numpy.take(fsim, ind, 0)\n",
    "        if callback is not None:\n",
    "            callback(sim[0])\n",
    "        iterations += 1\n",
    "        if retall:\n",
    "            allvecs.append(sim[0])\n",
    "\n",
    "    x = sim[0]\n",
    "    fval = numpy.min(fsim)\n",
    "    warnflag = 0\n",
    "\n",
    "    if fcalls[0] >= maxfun:\n",
    "        warnflag = 1\n",
    "        msg = _status_message['maxfev']\n",
    "        if disp:\n",
    "            print('Warning: ' + msg)\n",
    "    elif iterations >= maxiter:\n",
    "        warnflag = 2\n",
    "        msg = _status_message['maxiter']\n",
    "        if disp:\n",
    "            print('Warning: ' + msg)\n",
    "    else:\n",
    "        msg = _status_message['success']\n",
    "        if disp:\n",
    "            print(msg)\n",
    "            print(\"         Current function value: %f\" % fval)\n",
    "            print(\"         Iterations: %d\" % iterations)\n",
    "            print(\"         Function evaluations: %d\" % fcalls[0])\n",
    "\n",
    "    result = OptimizeResult(fun=fval, nit=iterations, nfev=fcalls[0],\n",
    "                            status=warnflag, success=(warnflag == 0),\n",
    "                            message=msg, x=x, final_simplex=(sim, fsim))\n",
    "    if retall:\n",
    "        result['allvecs'] = allvecs\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=1\n",
    "chi=2\n",
    "psi=0.5\n",
    "sigma=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -106.764537\n",
      "         Iterations: 41\n",
      "         Function evaluations: 81\n"
     ]
    }
   ],
   "source": [
    "sim = _minimize_neldermead(birds, [-5., -2.75], rho=rho, chi=chi, psi=psi, sigma=sigma, disp=True, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local optimal point is [-3.13024536 -1.58211848]\n",
      "Parameter values are [1, 2, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "x_star = sim.get('x')\n",
    "print(f'The local optimal point is {x_star}')\n",
    "print(f'Parameter values are {[rho, chi, psi, sigma]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=9\n",
    "chi=3\n",
    "psi=0.5\n",
    "sigma=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -1.873123\n",
      "         Iterations: 46\n",
      "         Function evaluations: 93\n"
     ]
    }
   ],
   "source": [
    "sim = _minimize_neldermead(birds, [-5., -2.75], rho=rho, chi=chi, psi=psi, sigma=sigma, disp=True, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local optimal point is [-3.94895657 -3.1089492 ]\n",
      "Parameter values are [9, 3, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "x_star = sim.get('x')\n",
    "print(f'The local optimal point is {x_star}')\n",
    "print(f'Parameter values are {[rho, chi, psi, sigma]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, if we change the parameters, then as we see it can converge but not quite to the local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Coordinate descend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomCoorDescent(f, x0, num_iter):\n",
    "    \n",
    "    x = x0\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "                \n",
    "        h = 0.01\n",
    "        \n",
    "        l = int(np.random.choice(2, 1))\n",
    "        \n",
    "        if l==0:\n",
    "            e = np.array([1, 0])\n",
    "        else:\n",
    "            e = np.array([0, 1])\n",
    "            \n",
    "        alpha = 1. / (i + 1) * 0.1\n",
    "        \n",
    "        x_new = np.copy(x)\n",
    "                \n",
    "        x_new[l] = x[l] - alpha * (f(x + h * e) - f(x)) / h\n",
    "        \n",
    "        if np.linalg.norm(f(x_new) - f(x)) < 1e-4:\n",
    "            return {'x': x_new, 'num_iter': i, 'f_val': f(x_new)}\n",
    "        \n",
    "        x = x_new\n",
    "        \n",
    "    return {'x': x_new, 'num_iter': i, 'f_val': f(x_new)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_{k+1}^{(i)} = x_{k}^{(i)} - \\alpha_k \\frac{f(x_k + h e_i) - f(x)}{h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "$$a_k = \\frac{1}{k} \\alpha_0$$\n",
    "$$\\alpha_0 = 0.1 \\ \\ \\ \\ h = 0.01$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_0 = (-4, -6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([-3.14770177, -7.82886918]),\n",
       " 'num_iter': 20,\n",
       " 'f_val': -87.19185486879636}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des = RandomCoorDescent(birds, [-4., -6.], 1000)\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local optimal point is [-3.1477017704401407, -7.828869176983157]\n"
     ]
    }
   ],
   "source": [
    "x_star = list(des['x'])\n",
    "print(f'The local optimal point is {x_star}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of function evaluations is number of iterations times 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of function evaluations is 40\n"
     ]
    }
   ],
   "source": [
    "f_eval = des['num_iter'] * 2\n",
    "print(f'The number of function evaluations is {f_eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local optimal value of the function is -87.19185486879636\n"
     ]
    }
   ],
   "source": [
    "val = des['f_val']\n",
    "print(f'The local optimal value of the function is {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, in this case we even managed to surpass Nelder Mead method, according to the speed of convergence, but this is just luck, besides this algorithm behaves unstably with this function and sometimes gives incorrect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([-5.37595502, -5.80657853]),\n",
       " 'num_iter': 20,\n",
       " 'f_val': 1.5426859101692936}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des = RandomCoorDescent(birds, [-4., -6.], 1000)\n",
    "des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For another initial point we have slightly different results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_0 = (-3, -4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([-3.12254517, -1.58732212]),\n",
       " 'num_iter': 121,\n",
       " 'f_val': -106.75263018128757}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des = RandomCoorDescent(birds, [-3., -4.], 1000)\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local optimal point is [-3.1225451720194837, -1.5873221168595228]\n"
     ]
    }
   ],
   "source": [
    "x_star = list(des['x'])\n",
    "print(f'The local optimal point is {x_star}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of function evaluations is 242\n"
     ]
    }
   ],
   "source": [
    "f_eval = des['num_iter'] * 2\n",
    "print(f'The number of function evaluations is {f_eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local optimal value of the function is -106.75263018128757\n"
     ]
    }
   ],
   "source": [
    "val = des['f_val']\n",
    "print(f'The local optimal value of the function is {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case Nelder Mead method performs better. But sometimes gives incorrect results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([nan, nan]), 'num_iter': 999, 'f_val': inf}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des = RandomCoorDescent(birds, [-3., -4.], 1000)\n",
    "des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(But this is simply due to the fact that we have defined the function in this way, in a good way, we can think of the reflection conditions from the boundaries or simply restart the cycle.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
